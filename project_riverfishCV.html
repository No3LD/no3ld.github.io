<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="format-detection" content="telephone=no, date=no, email=no, address=no">
  <title>Project: CV River Fish Monitoring | Noel D</title>
  <link rel="stylesheet" href="styles.css">
  <script defer src="https://cloud.umami.is/script.js" data-website-id="91b40b5d-5902-42ac-8314-b2b8b86278b7"></script>
</head>
<body>
<nav class="navbar">
  <div class="navbar__container">
    <a href="index.html" id="navbar__logo">
      <img src="assets/icons/Branding.svg" alt="Noel D Logo" class="navbar__logo-img">
    </a>
    <div class="navbar__toggle" id="mobile-menu">
      <span class="bar"></span>
      <span class="bar"></span>
      <span class="bar"></span>
    </div>
    <ul class="navbar__menu">
      <li class="navbar__item">
        <a href="index.html" class="navbar__links">Home</a>
      </li>
      <li class="navbar__item">
        <a href="projects.html" class="navbar__links active">Projects</a>
      </li>
      <li class="navbar__item">
        <a href="experience.html" class="navbar__links">Experience</a>
      </li>
      <li class="navbar__item">
        <a href="about_me.html" class="navbar__links">About Me</a>
      </li>
      <li class="navbar__item">
        <a href="contact.html" class="navbar__links">Contact</a>
      </li>
      <li class="navbar__btn">
        <a href="assets/experience/CV-Noel-Dunning.pdf" download="NoelD_CV" class="button">CV</a>
      </li>
    </ul>
  </div>
</nav>

<main>
  <section class="content__section">

    <h1 style="margin-bottom: 3rem;">Riverfish Computer Vision</h1>

    <div class="details__container">

      <div class="detail-row">
        <div class="detail-text">
          <h2>Overview</h2>
          <p>
            RiverEye is my personal project, which aims to improve the monitoring of local populations of freshwater fish in midwest rivers using deep learning based object detection and image classification models.
          </p>
        </div>
        <div class="detail-image">
          <img src="images/fish_2_thumbnail.png" alt="Overview Image">
        </div>
      </div>

      <div class="detail-row">
        <div class="detail-text">
          <h2>Target Problem</h2>
          <p>
            Manual monitoring of fish populations is invasive, time-consuming, and prone to human inconsistency. This tool would allow researchers and Natural Resource Departments to gather accurate data on local populations without the need for manually filtering through large swaths of video or physically netting fish. This saves time, and ensures that researchers can focus on interpreting data and making informed ecological decisions, while minimizing the impact of monitoring on aquatic wildlife. Additionally, enabling Natural Resource Departments to more quickly and effectively identify and quantify populations of invasive species ensures that they can act rapidly to protect native species.
          </p>
        </div>
        <div class="detail-image">
          <img src="images/problem_carp.jpg" alt="Problem Context Image">
        </div>
      </div>

      <div class="detail-row">
        <div class="detail-text">
          <h2>Goals</h2>
          <p>
            This project has three main goals: <br>
            1. Develop an object detection model with high accuracy and precision for low-medium quality images with varying light and visibility conditions (Target mAP >= 0.98). <br>
            2. Develop an image classification model that can identify common Midwestern species, game species, and invasive species reliably (Target mAP >= 0.95). <br>
            3. Deploy both models into an application for use by researchers and Natural Resource Departments.
          </p>
        </div>
        <div class="detail-image">
          <img src="images/process.png" alt="Goals Image">
        </div>
      </div>

      <div class="detail-row">
        <div class="detail-text">
          <h2>Dataset</h2>
          <p>
            Data was acquired from Dr. Cory Suski's Lab (Justin Lombardo, MS Student) in the Natural Resources Department at the Univeristy of Illinois. The dataset included ~2 hours of total footage. Footage was captured using a stationary camera aimed at Bass Nests and using an underwater camera while diving. This dataset was specifically acquired to be diverse in terms of quality, lighting, and general visibility so that the model would be able to maintain accuracy in these situations. Data for the preliminary classifier model was found primarily online from reputable, legal sources. <br> <br>
            After receiving the raw video data, I split the videos into frames, and ran software to remove images with a high degree of similarity (>0.85). After creating a base set of images, I uploaded the dataset to CVAT where I began the labeling process for the object detection model. The preliminary object detection model training set consisted of 500 labeled images.<br><br>
            Data for the preliminary classifier was separated into 10 folders; One for each species of fish. Each folder contained 15 images for a total training set of 150 images.
          </p>
        </div>
        <div class="image-stack">
          <div class="detail-image">
            <img src="images/data1.png" alt="Dataset Image 1">
          </div>
          <div class="detail-image">
            <img src="images/data2.png" alt="Dataset Image 2">
          </div>
        </div>
      </div>

      <div class="detail-row">
        <div class="detail-text">
          <h2>Preliminary Models</h2>
          <p> Preliminary models for both object detection and classification were trained using an 80-20 train/val split and used a pretrained YOLOv8 model as a foundation. They were trained on 30 epochs and 60 epochs respectively.<br><br>
            Validation on the preliminary object detection model showed mean average precision at 0.91 (mAP = 0.91). This demonstrates proof of concept and indicates that expansions on the dataset and fine-tuning of parameters will yield subsequent performance improvements. <br><br>
            Preliminary classifier validation also demonstrated proof of concept and potential for improvements, with the model struggling when species were closely related, but performing reliably on unique target species such as the invasive Asian carp. Results are summarized in the adjacent confusion matrix.

          </p>
        </div>
        <div class="image-stack">
          <div class="detail-image">
            <img src="images/fishdetect_1.jpg" alt="Object Detection Image">
          </div>
          <div class="detail-image">
            <img src="images/fish_classifier_confmat.png" alt="Confusion Matrix">
          </div>
        </div>
      </div>

      <div class="detail-row">
        <div class="detail-text">
          <h2>Current Objectives</h2>
          <p>
            Data labeling is the current objective of RiverEye. I have ~5000 images that will make up the dataset for my newest detection model version, which will be trained locally using YOLOv11. They contain images with variable quality, environments, and fish from sections of the Illinois River, which I hope will contribute strongly to the robustness of subsequent detection models.
          </p>
        </div>
        <div class="detail-image">
          <img src="images/cvat.png" alt="Future Work Image">
        </div>
      </div>

    </div>
  </section>
</main>
<footer class="footer__container">
  <p>&copy; 2026 Dunning, Noel. All rights reserved.</p>
</footer>

<script src="app.js"></script>
</body>
</html>